                 #高并发秒杀项目及其优化
                 #概述
   本项目主要功能是模拟实现一个秒杀场景，由最初的极少数据存储量和
极少的访问量，逐渐演变为万级别的数据存储量和访问量；整个秒杀系统
在大量数据演变的过程中如何做到高可用，高并发。  

##项目架构
   本项目使用 Maven 构建，后台框架采用的是 Spring+Mybatis+SpringMVC,
前端页面采用 Bootstrap+JQuery；关系型数据库采用的是 MySQL，并且用
Redis做热点商品的缓存。项目启动的服务器是一台 Tomcat,压测工具采用的
是 Jmeter。  

 ##项目运行流程  
 
   该项目严格遵守秒杀系统的业务流程，商家+库存+用户三者之间进行信息交
 互，商家需要在库存中添加商品，修改商品信息等；而用户会对库存中的商
 品进行秒杀或者预购。  
 
 站在后台开发人员的角度执行一次秒杀业务要经过以下几个过程：  
 
 1、首先进入商品详情页，点击某个商品的秒杀按钮，对后台来说就是客户端发送了一个关于秒杀
    的url。(由于秒杀业务肯定在用户登录系统的前提下进行的，所以不考虑用户的登录状态)  
    
 2、url通过SpringMVC的控制进入系统的Controller层，找到执行秒杀的方法，
    执行秒杀操作。  
    
 3、首先系统会根据用户所秒杀的商品id在Redis中查找到商品(如果查询失败，那么在 MySQL中查找)，
    然后生成一段密文返回给用户，然后在根据这个密文执行减库存和添加购买明细(这两步构成一个
    完整的数据库事务)操作。  
    
 4、秒杀成功或者失败，将结果返回给用户。  
 
  #项目核心技术+并发优化
   优化1：由于商品的库存信息一般需要安全的落地在磁盘上，并且秒杀
   这个业务场景又具有很强的事务性，所以优先选用了MySQL数据库做商品
   信息的持久化；由此也带来了一个问题，由于MySQL数据库对事务的支持
   比较严格，当多个用户想要同时去秒杀同一样商品时，有且仅有一个用户
   会获得秒杀权限，执行秒杀；而其他的竞争者在秒杀用户没有结束前是不能
   对该商品进行秒杀的。在这里采用了MySQL默认的事务隔离级别，可重复读
   支持多个用户可以多次重复执行同一个事务，而不需要获得对应的行级锁
   （当事务的隔离级别时串行化时，系统在执行事务时对数据加的是表级锁）  
   
   # MVCC
   MySQL的innodb引擎是如何实现MVCC的。innodb会为每一行添加两个字段，分别
   表示该行创建的版本和删除的版本，填入的是事务的版本号，这个版本号随着事务
   的创建不断递增。在repeated read的隔离级别（事务的隔离级别请看这篇文章）下，具体各种数据库操作的实现：
   select：满足以下两个条件innodb会返回该行数据：（1）该行的创建版本号小于等于当前版本号，用于保证在select操作之前所有的操作已经执行落地。（2）该行的删除版本号大于当前版本或者为空。删除版本号大于当前版本意味着有一个并发事务将该行删除了。
   insert：将新插入的行的创建版本号设置为当前系统的版本号。
   delete：将要删除的行的删除版本号设置为当前系统的版本号。
   update：不执行原地 update，而是转换成 insert + delete。将旧行的删除版本号设置为当前版本号，并将新行insert同时设置创建版本号为当前版本号。
   其中，写操作（insert、delete和update）执行时，需要将系统版本号递增。
   由于旧数据并不真正的删除，所以必须对这些数据进行清理，innodb会开启一个后台线程执行清理工作，具体的规则是将删除版本号小于当前系统版本的行删除，这个过程叫做purge。
   通过 MVCC 很好的实现了事务的隔离性，可以达到repeated read级别  
   
   
   优化2：利用CDN做静态界面的缓存，使得用户可以更快的获得秒杀列表的商品信息
   
   优化3：由于获得秒杀接口，只是一个简单的查询操作；并不会修改库存信息
   但是，大量用户将会请求获得同一个秒杀接口，从而才有机会成功秒杀到具体的商品；
   大量的用户中只有一部分很少的用户会成功秒杀到商品，执行真正的秒杀
   事务，其他用户将会被拒绝。在 MySQL 中的数据都落地在物理磁盘上，每次读取
   商品信息都需要大量的IO操作，频繁的从用户态和内核态copy数据会浪费大量
   cpu时间，以及耗费大量的时间。所以，在获得秒杀接口这一步中，可以从Redis
   中读取数据，只有第一个请求该秒杀接口的用户需要从磁盘中读取商品数据，读取到该数据后
   将会把它移步到Redis缓存中，Redis中的数据都存储在内存中，从而使得用户可以用极少的
   时间就获得秒杀接口，从而8执行秒杀事务。
 （为什么需要定义一个秒杀接口？
     为了防止“刷客”提前破解了秒杀地址，使得商品在秒杀还没有开启时就别洗劫一空
     总得来说也是为数据安全性又做了一层保障；
     另外一个好处是减缓了服务器的压力，不会出现所有的用户用时登录后，直接进行秒杀
     事务；导致数据库雪崩。
  ）
 （为什么不用Mybatis自带的缓存机制？
 
    一级缓存：（session statement两种级别）
    当然，在每次通过Mybatis的映射文件去执行动态SQL时，都会首先通过
    一级缓存查询；如果缓存中查找到了本次SQL语句所要查询的内容；那么
    直接返回；就不用去数据库中根据索引查找了，这样便避免了大量的IO操作
    当然反之如果缓存中没有要查找的数据，那么就必须从数据库中查询
    并且将返回后的数据存储在缓存中。
    一次缓存的实现很简单：底层维系了一个HashMap,根据查询类型 参数个数 以及
    本次查询的数据在数据库中的位置 作为key来唯一标识一次SQL查询；将查询
    到的数据作为value;
    
    那么问题来了，如何判断两次SQL查询的内容完全一样呢？（也就是说如何比较key相等）
    条件一：判断statementId是否相同，也就是说是否为同一类型的查询。
    条件二：根据Mybatis自带的分页功能，确定本次查询的结果集在数据库中的具体位置
    条件三：调用SQL语句时，传入的SQL语句要完全一样
    条件四：两次传递给JDBC的参数也相同，保证同一个数据源连接
    
    一级缓存的问题：大体来说就是粗粒度，不安全 ；具体表现在以下问题：
      -->不会判断缓存中的数据是否已经过期，更不会更新缓存中的数据
     解决方案：高时效的控制 SqlSession 的生命周期，进而控制缓存行的有效性。
     
     二级缓存
     如果用户在刚开始配置了"cacheEnabled = true";那么Mybatis在创建Executor
     的同时，为他创建一个装饰者对象CachingExecutor;对于用户端的一个查询请求
     会首先判断二级缓存中是否有数据，如果有直接返回；如果没有，那么交给Executor
     继续执行查询操作。
     优势：粒度更细，每一个Mapper支持一个缓存节点,提供了各种缓存刷新策略（LRU），
     并且支持第三方的缓存库 比如 Memecached
     
     缓存顺序：二级缓存->一级缓存->数据库
     项目中不用Mybatis做缓存的主要原因是，在大型电商系统中，查询的数据量都是批量的
     并且大多需要多表关联查询；但是Mybatis二级缓存不支持这种多表关联数据缓存；而是基于
     一个namespace的； 
  ）
  优化4：当商品种类特别大时，商品表的规模就会很大；数据量过大，导致执行秒杀时，在商品
  表中执行减库存的操作将会特别缓慢，解决方案是将数据采用路由hash算法分离到多个数据库中，
  并且每个主数据库都搭配一个备库，copy主库中的所有数据，分担主库读的压力。
  
   
    
   

